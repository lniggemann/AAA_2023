{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lniggemann/AAA_2023/blob/main/Abgabe_2_sigmoid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vowXhTYeiHzM"
      },
      "source": [
        "![Logo Uni KÃ¶ln](https://raw.githubusercontent.com/jmelsbach/ai-im/main/img/uni-logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDZKPe2Tw82W"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y41hBuN0SIOx"
      },
      "source": [
        "Group Members\n",
        "\n",
        "Team DaLeMaNi: \n",
        "* Daniel Becker\n",
        "* Leo Niggemann\n",
        "* Marc Asbach\n",
        "* Nick Bacher\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8uk9HnwiUik"
      },
      "source": [
        "# Exercise 03 Notebook - Text Classification with BERT\n",
        "In this notebook we will create a Neural Network for Text Classification. As a basis for our Network we will use a pretrained BERT Model and just add a classification layer. We will train and test our dataset on the IMDB dataset we have already seen in the previous exercises."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88XYrS4ajzlP"
      },
      "source": [
        "## 1. Download the data, model , and tokenizer\n",
        "In a first step we will install transformers, an awesome library by huggingface that implements a lot of transformer models and also provides pretrained models in many languages that we can download and use for free."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvGYkUUJ5_VX",
        "outputId": "eb31db16-b068-4f44-e026-9ae42f2b4010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n"
          ]
        }
      ],
      "source": [
        "# install transformer library via pip\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9448Mx8lCHT"
      },
      "source": [
        "Before we download a pretrained model, we download the data we will train our classifier on. Read the data from `https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv` into a pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8oidZKgWlZxD"
      },
      "outputs": [],
      "source": [
        "# import pandas\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DXJYl2l4IYCJ",
        "outputId": "f72089f2-a1c4-468f-a020-6f7c9838128e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  My family and I normally do not watch local mo...          1\n",
              "1  Believe it or not, this was at one time the wo...          0\n",
              "2  After some internet surfing, I found the \"Home...          0\n",
              "3  One of the most unheralded great works of anim...          1\n",
              "4  It was the Sixties, and anyone with long hair ...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06215eaf-78f8-4101-9e9d-8009bf625ba9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My family and I normally do not watch local mo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Believe it or not, this was at one time the wo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>After some internet surfing, I found the \"Home...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>One of the most unheralded great works of anim...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06215eaf-78f8-4101-9e9d-8009bf625ba9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06215eaf-78f8-4101-9e9d-8009bf625ba9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06215eaf-78f8-4101-9e9d-8009bf625ba9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Read the csv file and save it in a variable called data_df\n",
        "data_df = pd.read_csv(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\")\n",
        "data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Pv-I_pPPpVHW",
        "outputId": "e0233c59-8e85-44a7-ee0f-990260ab0949"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  \"Amazing Grace\" has a languid feel to it as it...          1\n",
              "1  Redo the Oscars from 1992, and this film might...          1\n",
              "2  The film isn't perfect by any means but despit...          1\n",
              "3  Critters 4: This movie was continued after the...          1\n",
              "4  I can't believe the likes of Guillermo del Tor...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f0435e4-7957-4816-882c-dc7d65d377e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"Amazing Grace\" has a languid feel to it as it...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Redo the Oscars from 1992, and this film might...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The film isn't perfect by any means but despit...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Critters 4: This movie was continued after the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I can't believe the likes of Guillermo del Tor...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f0435e4-7957-4816-882c-dc7d65d377e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f0435e4-7957-4816-882c-dc7d65d377e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f0435e4-7957-4816-882c-dc7d65d377e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# After reading in the data, shuffle the rows of the DataFrame\n",
        "data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
        "data_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeLOUOaWwb_0"
      },
      "source": [
        "If you forget how the dataset looks like to a little bit of of data exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9BzebVVwrXW",
        "outputId": "3b62371a-ae01-49d5-e61f-b4dc552f5b22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Data Exploration\n",
        "data_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi9rqmsxd0OQ",
        "outputId": "65755004-6d7f-4336-a3f9-51a7db104299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 781.4+ KB\n"
          ]
        }
      ],
      "source": [
        "data_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HtLtRgapslR"
      },
      "source": [
        "A lot of errors can happen when you build your dataset and model for the first time. It neat little trick is to not use all of your data from the beginning. The IMDB dataset we use has 50,000 training examples. To see if everything works we dont need to use all of our data. A small subset is enough, so it might be useful to just take 1000 examples at first and only use the full data at the very end when we no that everything works as intended."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XUfaquLPpls2"
      },
      "outputs": [],
      "source": [
        "# get the first 1000 rows of the dataframe\n",
        "data_df = data_df.head(1000) # TODO = wegmachen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OJjGt00spNJy"
      },
      "outputs": [],
      "source": [
        "# Make an 80:20 split for training and validation data and save\n",
        "# them as train_df and val_df, respectively.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(data_df, test_size=0.2)\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "val_df = val_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeUL-GFVe_QQ",
        "outputId": "846e1571-bf08-4a27-cbd4-e307d971004b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Size: 800\n",
            "Validation Size: 200\n"
          ]
        }
      ],
      "source": [
        "print(\"Training Size: \"+str(len(train_df)))\n",
        "print(\"Validation Size: \"+str(len(val_df)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge5ie7hClmKu"
      },
      "source": [
        "Great! Now that we have our data at hand we will now download the pretrained BERT Model. To be more precise we will use a smaller version of BERT named DistilBERT which is a lot smaller than the normnal BERT model but has 95% of it's performance.\n",
        "\n",
        "\n",
        "\n",
        "> The DistilBERT model was proposed in the blog post Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT, and the paper DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. DistilBERT is a small, fast, cheap and light Transformer model trained by distilling BERT base. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERTâs performances as measured on the GLUE language understanding benchmark.\n",
        "\n",
        "A smaller model allows much faster training and it makes much sense to try out ideas with a smaller model, because we can iterate much faster with a smaller model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9kd_Uo6r6VOI"
      },
      "outputs": [],
      "source": [
        "# import model and tokenizer classes\n",
        "from transformers import DistilBertModel, DistilBertTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5IbyGwAnpwI"
      },
      "source": [
        "The transformer library makes it very easy for us to download pretrained versions of a model and the corresponding tokenizer. You can find a pretrained model [here](https://huggingface.co/distilbert-base-uncased). You could try out more models.\n",
        "\n",
        "As already mentioned we want to use DistilBert for our classifier. Try to find a suitable model that we can use for our dataset and save it's name as a string in a variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "s419l5b4oWIk"
      },
      "outputs": [],
      "source": [
        "# insert model name\n",
        "model_name = \"distilbert-base-uncased\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEWJsJbk6xeI",
        "outputId": "0ce223c9-f8fc-40a5-fbfc-7dc490891e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "bert_model = DistilBertModel.from_pretrained(model_name)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cVcneG8ovIj"
      },
      "source": [
        "## 2. Tokenizer\n",
        "After successfully downloading the pretrained model and tokenizer will use the  tokenizer to tokenize our text data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVB4CG02uXLa"
      },
      "source": [
        "### 2.1 Getting familiar with the tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e2_5CVVrjCo"
      },
      "source": [
        "As a little warm-up lets do a few exercises on the example text given below. If you don't know what to do have a look at the [tokenizer documentation](https://huggingface.co/transformers/main_classes/tokenizer.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JuMkIpAqrqq9"
      },
      "outputs": [],
      "source": [
        "example_text = \"\"\"Star wars made epic fantasy real. For a generation of people it has defined what the cinema experience is meant to be.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naSc8pEvN4jM",
        "outputId": "34ff3f0e-23a6-49bf-bfbf-e302320a1a66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['star',\n",
              " 'wars',\n",
              " 'made',\n",
              " 'epic',\n",
              " 'fantasy',\n",
              " 'real',\n",
              " '.',\n",
              " 'for',\n",
              " 'a',\n",
              " 'generation',\n",
              " 'of',\n",
              " 'people',\n",
              " 'it',\n",
              " 'has',\n",
              " 'defined',\n",
              " 'what',\n",
              " 'the',\n",
              " 'cinema',\n",
              " 'experience',\n",
              " 'is',\n",
              " 'meant',\n",
              " 'to',\n",
              " 'be',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# tokenize the example_text\n",
        "# you should receive a list ['Star', 'wars', 'made', ..., '.']\n",
        "# first we build a list of tokens from the sentence \n",
        "example_list = tokenizer.tokenize(example_text)\n",
        "example_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAOSti7SN0Bm",
        "outputId": "31da5280-642d-4336-fcca-896d755cb825"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 2732,\n",
              " 5233,\n",
              " 2081,\n",
              " 8680,\n",
              " 5913,\n",
              " 2613,\n",
              " 1012,\n",
              " 2005,\n",
              " 1037,\n",
              " 4245,\n",
              " 1997,\n",
              " 2111,\n",
              " 2009,\n",
              " 2038,\n",
              " 4225,\n",
              " 2054,\n",
              " 1996,\n",
              " 5988,\n",
              " 3325,\n",
              " 2003,\n",
              " 3214,\n",
              " 2000,\n",
              " 2022,\n",
              " 1012,\n",
              " 102]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# encode the example text.\n",
        "# you should receive a list of integers [101, 2537, 8755, ..., 102]\n",
        "# save the list into a variable encoded_text\n",
        "# The IDs we get are from the pretrained model that already has a list of token-ID pairs\n",
        "encoded_text = tokenizer.encode(example_list)\n",
        "encoded_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgaMk6BJOCxG",
        "outputId": "e9a761bb-974b-4161-acb3-0de3a0eb77a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] star wars made epic fantasy real. for a generation of people it has defined what the cinema experience is meant to be. [SEP]\n",
            "We notice the 'CLS' (token 101) and 'SEP' (token 102) Values in the front and in the back.\n"
          ]
        }
      ],
      "source": [
        "# use the tokenizer to decode the encoded_text\n",
        "# do you notice something?\n",
        "decoded_text = tokenizer.decode(encoded_text)\n",
        "print(decoded_text)\n",
        "print(\"We notice the 'CLS' (token 101) and 'SEP' (token 102) Values in the front and in the back.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZoBEIzXtYqk",
        "outputId": "e9004ca6-44dd-473b-95ae-254fe7d125a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 2732, 5233, 2081, 8680, 5913, 2613, 1012, 2005, 1037, 4245, 1997, 2111, 2009, 2038, 4225, 2054, 1996, 5988, 3325, 2003, 3214, 2000, 2022, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
            "We receive an object that has the IDs and an attention mask.\n",
            "Each ID is a token index, numerical representations of tokens that are already stored in the pretrained model\n",
            "CLS stands for Classification, SEP seperates a sentence from a new one\n",
            "For the BertTokenizer, 1 indicates a value that should be attended to, while 0 indicates a padded value.\n"
          ]
        }
      ],
      "source": [
        "# use the tokenizer object as a function and use the\n",
        "# example_text as the input. What type of object do you receive?\n",
        "# What does each value mean?\n",
        "\n",
        "print(tokenizer(example_text))\n",
        "print(type(tokenizer(example_text)))\n",
        "# https://huggingface.co/transformers/v3.2.0/glossary.html#input-ids fand ich hilfreich\n",
        "print(\"We receive an object that has the IDs and an attention mask.\") \n",
        "print(\"Each ID is a token index, numerical representations of tokens that are already stored in the pretrained model\")\n",
        "print(\"CLS stands for Classification, SEP seperates a sentence from a new one\")\n",
        "print(\"For the BertTokenizer, 1 indicates a value that should be attended to, while 0 indicates a padded value.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNybb_B1ucqp"
      },
      "source": [
        "### 2.2 Tokenizing the data\n",
        "We are now ready to tokenize our test and validation dataset. Again use the tokenizer to create input_ids and attention_masks for the test and validation set. The tokenized text should have the following properties:\n",
        "* [CLS] and [SEP] token added\n",
        "* max length should be 128\n",
        "* texts with more than 128 tokens should be truncated\n",
        "* the tokenizer should return torch tensors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJo5NL97XcMC",
        "outputId": "e78ddbca-8da6-4324-8e1d-48edbb646422"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  1045,  2131,  ...,  2087, 18691,   102],\n",
              "        [  101,  1045,  1005,  ...,  1996, 10558,   102],\n",
              "        [  101,  2009,  4165,  ..., 12996,  2102,   102],\n",
              "        ...,\n",
              "        [  101,  2023,  2307,  ...,     0,     0,     0],\n",
              "        [  101,  2023,  3185,  ...,     0,     0,     0],\n",
              "        [  101,  1997,  2035,  ...,  1010,  2209,   102]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Apply the tokenizer to the training text data and save the resulting dict\n",
        "# in a variable called tokenized_val_data // Nehme mal an das hier war ein Fehler in der Aufgabenstellung\n",
        "\n",
        "tokenized_train_data = tokenizer(list(train_df[\"review\"]), return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
        "tokenized_train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KdLaFwRfP3O",
        "outputId": "62d2043b-15bf-4add-d81c-ad8cd0b1f775"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  1045,  1005,  ...,  5790,  1006,   102],\n",
              "        [  101,  5356,  2075,  ...,  2014,  5160,   102],\n",
              "        [  101,  1045,  6135,  ...,  2097,  2763,   102],\n",
              "        ...,\n",
              "        [  101,  2152,  2082,  ...,  2023,  2003,   102],\n",
              "        [  101,  2026,  2564,  ...,     0,     0,     0],\n",
              "        [  101,  7687,  5436,  ...,  2070, 13372,   102]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Apply the tokenizer to the validation text data and save the resulting dict\n",
        "# in a variable called tokenized_train_data // Nehme mal an das hier war ein Fehler in der Aufgabenstellung\n",
        "tokenized_val_data = tokenizer(list(val_df[\"review\"]), return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
        "tokenized_val_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzCZ8ypYXfMv",
        "outputId": "289734eb-4ccc-4c99-9028-c53be0f5c62f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  1045,  2131,  ...,  2087, 18691,   102],\n",
              "        [  101,  1045,  1005,  ...,  1996, 10558,   102],\n",
              "        [  101,  2009,  4165,  ..., 12996,  2102,   102],\n",
              "        ...,\n",
              "        [  101,  2023,  2307,  ...,     0,     0,     0],\n",
              "        [  101,  2023,  3185,  ...,     0,     0,     0],\n",
              "        [  101,  1997,  2035,  ...,  1010,  2209,   102]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# have a look at the input_ids of the tokenized_train_data\n",
        "tokenized_train_data[\"input_ids\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ynf_QqS7XwUb",
        "outputId": "ff7691fb-65f0-4b61-c90d-ce0554a3db1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# have a look at the attention_mask of the tokenized_train_data\n",
        "tokenized_train_data[\"attention_mask\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLmYtMOXwDIJ"
      },
      "source": [
        "## 3. Creating the test and validation Dataset and DataLoader\n",
        "Our train and evaluation data in vector format and we can now use the tokenized text to create our Dataset and DataLoader class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KTYWyiVBXOiG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# import Dataset and DataLoader class\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMwTMKT7xLly"
      },
      "source": [
        "Now create a Dataset class called TextDataset. As always we will need to implement three functions:\n",
        "* `__init__`\n",
        "* `__len__`\n",
        "* `__getitem__`\n",
        "\n",
        "The `__init__` function should take tokenized data and the labels as arguments\n",
        "and store them into the class variables `X` and `Y`\n",
        "\n",
        "The `__len__` function should return the length of the dataset\n",
        "\n",
        "The `__getitem__` should take index as input and return a tuple of data that looks like this `(input_ids, attention_mask, labels)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WMcFKxygZW93"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X, Y):\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "  \n",
        "  def __len__(self,):\n",
        "    return len(self.Y)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return (self.X[\"input_ids\"][index], self.X[\"attention_mask\"][index], self.Y[index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5jr3430yX1P"
      },
      "source": [
        "Create a `train_dataset` and `val_dataset`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "AH4cudPNZXz3"
      },
      "outputs": [],
      "source": [
        "train_dataset = TextDataset(tokenized_train_data, train_df[\"sentiment\"])\n",
        "val_dataset = TextDataset(tokenized_val_data, val_df[\"sentiment\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFXy1Mt0TSKr",
        "outputId": "997350de-d153-48ef-cddb-ad4737f1b89b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.TextDataset at 0x7f0d296bb760>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbuWY7dLyzVw"
      },
      "source": [
        "Create the training DataLoader `train_dl` and the validation DataLoader `val_dl` with a batch size of 32:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ntTFu3O8yxzp"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dl = DataLoader(val_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0LuKmmnQpPQ",
        "outputId": "848dc296-dedc-4da9-8662-bf51372db5f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f0d296bbd30>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "train_dl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6rsG6VVzfpn"
      },
      "source": [
        "# 4. Creating the Model\n",
        "In this part we will create our model using the pretrained DistilBert model that we downloaded at the beginning. Before we add our classifier to the network we first need to understand what exactly the DistilBert models output looks like."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HkrcYJEgQJ3"
      },
      "source": [
        "### 4.1 Understanding BERT's output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wwfDXGZr1xsE"
      },
      "outputs": [],
      "source": [
        "# get the first batch from our train_dl\n",
        "first_batch = next(iter(train_dl))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ool4ysw53TON"
      },
      "source": [
        "Have a look at the `first_batch`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKcHyYbv5czd",
        "outputId": "702339b0-51f1-4f0f-9c89-ae79b0fddb9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[  101,  1000,  1037,  ...,  8649,  4212,   102],\n",
              "         [  101,  1045,  2071,  ...,  2069,  2366,   102],\n",
              "         [  101,  1996,  3624,  ...,  2189,  2158,   102],\n",
              "         ...,\n",
              "         [  101,  1000, 24209,  ...,  2024, 27427,   102],\n",
              "         [  101,  1045,  2031,  ...,  4030,  4367,   102],\n",
              "         [  101,  2045,  1005,  ...,  5621,  3866,   102]]),\n",
              " tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1]]),\n",
              " tensor([0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "         0, 1, 0, 1, 1, 1, 0, 1])]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# first batch\n",
        "first_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEewu3Pp3pbd"
      },
      "source": [
        "Save the input ids in a variable called `input_ids` and the attention mask into an variable called `attention_mask`. You can ignore the labels for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO53dijPgUsM",
        "outputId": "86230bb1-02d9-4b5c-9a38-f5e8393daaa7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  1000,  1037,  ...,  8649,  4212,   102],\n",
              "        [  101,  1045,  2071,  ...,  2069,  2366,   102],\n",
              "        [  101,  1996,  3624,  ...,  2189,  2158,   102],\n",
              "        ...,\n",
              "        [  101,  1000, 24209,  ...,  2024, 27427,   102],\n",
              "        [  101,  1045,  2031,  ...,  4030,  4367,   102],\n",
              "        [  101,  2045,  1005,  ...,  5621,  3866,   102]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "input_ids = first_batch[0]\n",
        "input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if8wdNY_66pG",
        "outputId": "7383b0fa-6654-4f81-9adb-5fe1317e6917"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "attention_mask = first_batch[1]\n",
        "attention_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK6a6FIZ4Ewj"
      },
      "source": [
        "In the first chapter we downloaded the pretrained DistilBert Model and saved it as `bert_model`. For the forward propagation the `bert_model`expects input ids and attention masks as an input. [This blog](https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/) post is a very nice visualization and is very helpful for understanding coming out of the bert model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRgXKzKR2a0n"
      },
      "source": [
        "![Last hidden state](https://jalammar.github.io/images/distilBERT/bert-output-tensor-selection.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "1dwETN2r5YoK"
      },
      "outputs": [],
      "source": [
        "last_hidden_state = bert_model(input_ids, attention_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tjm08CGHekvq"
      },
      "source": [
        "Check the dimension of the models output and make sure you understand what each dimension represents. Slice the model so that you get all values for each `[CLS]` token in the batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hhTk801et9I",
        "outputId": "7610b8e4-381b-4252-b841-188732fe05dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 128, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# shape of last hidden state\n",
        "last_hidden_state[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th1yaUglfd9u",
        "outputId": "2da24bc9-c862-44bd-8552-fe64a3476f2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1422, -0.2779,  0.0791,  ..., -0.0693,  0.5400,  0.4380],\n",
              "        [ 0.1542, -0.1657, -0.0016,  ..., -0.0842,  0.3681,  0.3049],\n",
              "        [ 0.0339, -0.1982, -0.0868,  ..., -0.1130,  0.5519,  0.3253],\n",
              "        ...,\n",
              "        [-0.2462,  0.0997, -0.1050,  ..., -0.0734,  0.5350,  0.2770],\n",
              "        [-0.0789, -0.2745, -0.1477,  ...,  0.1073,  0.5311,  0.4000],\n",
              "        [-0.1087, -0.1274,  0.0492,  ..., -0.1063,  0.4737,  0.0610]],\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Select [CLS] Token\n",
        "# CLS Token is the first position\n",
        "last_hidden_state[0][:,0,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kUUvsvQf722",
        "outputId": "16c02d77-9bdf-4784-b923-969a59e52265"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# check the shape of the [CLS] tokens\n",
        "last_hidden_state[0][:,0,:].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5Es53OwgZIt"
      },
      "source": [
        "### 4.2 Defining the Model\n",
        "Now create a neural network called `BertClassifier`. The constructor should receive the pretrained bert model and the number of classes.\n",
        "In the constructor save the bert model into a variable `bert`. Create a linear layer and think which input and output dimensions are needed.\n",
        "\n",
        "The `forward()` should receive `input_ids` and `attention_mask` as input and should propate them through the layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "eht1dRbBaZtA"
      },
      "outputs": [],
      "source": [
        "# implement BertClassifier\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, bert_model, n_classes):\n",
        "    super().__init__()\n",
        "    self.bert = bert_model\n",
        "    self.L1 = nn.Linear(768, n_classes)\n",
        "    self.activation = nn.Sigmoid() # Sigmoid is recommended for binary tasks # TODO #nn.GELU() #in BERT we use GELU instead of ReLu\n",
        "\n",
        "  def freeze_bert(self):\n",
        "    for param in self.bert.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    # feed input to bert\n",
        "    X = self.bert(input_ids, attention_mask)\n",
        "    # extract [CLS] for the classification\n",
        "    X = X.last_hidden_state[:, 0, :]\n",
        "    #print(X)\n",
        "    #X = torch.flatten(X, start_dim=1)\n",
        "\n",
        "    X = self.L1(X) \n",
        "    X = self.activation(X)\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "GmqxoH9bcU-X"
      },
      "outputs": [],
      "source": [
        "# instiantiate the model\n",
        "model = BertClassifier(bert_model=bert_model, n_classes=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBS6Zo4ctfKC"
      },
      "source": [
        "## 5. Model Training\n",
        "After defining the model we now have everything we need to train our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywZHOUdHxA2a"
      },
      "source": [
        "### 5.1 Moving to the GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_79GWPUubFF"
      },
      "source": [
        "In previous exercises our models were quite small with only a couple of thousand parameters. Our BERT classifier is several magnitudes larger (about 66M parameters). With that many parameters it becomes necessary to train on the gpu.\n",
        "\n",
        "We can easily move our model to the gpu with the following command:\n",
        "  `model.to('gpu')`. But there is one problem. If there is no 'gpu' available the code will crash. There is an easy way to check if a gpu is available:\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EId8J2Iev5tT",
        "outputId": "104ccb16-3251-405a-f5d7-bb2a00250e5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__VP6sZ9wc67"
      },
      "source": [
        "We can now move our model to the gpu safely. If there is no gpu available the model just stays on the cpu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QACcTLD7cfPa",
        "outputId": "9bdeb0ac-e780-48fa-ca94-d376115132a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertClassifier(\n",
              "  (bert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (L1): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (activation): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# pass the model to the gpu\n",
        "model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNOxzW_ewtAP"
      },
      "source": [
        "### 5.2 Setting up the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ebgzspzldym3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "epochs = 30\n",
        "lr = 0.0025\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "#loss_func = nn.CrossEntropyLoss()\n",
        "loss_func = nn.BCEWithLogitsLoss() # Binary Cross Entropy Loss\n",
        "#loss_func = nn.NLLLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Wl2N3WAod6-P"
      },
      "outputs": [],
      "source": [
        "# To get a better idea of how well your model performs\n",
        "# you should implement an accuracy function that is\n",
        "# called after each epoch of your training loop\n",
        "def accuracy(out, yb):\n",
        "  pred = out > 0.5\n",
        "   # preds = torch.argmax(out, dim=1)\n",
        "    #print(preds == yb)\n",
        "    #return accuracy = metrics.accuracy_score(y_true, y_prob > 0.5)\n",
        "  return (pred == yb).float().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "oYpQEvJcxK7z"
      },
      "outputs": [],
      "source": [
        "# Freezing Parameters of bert\n",
        "\n",
        "model.freeze_bert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKFG6nNHxYG1"
      },
      "source": [
        "### 5.3 Train the model\n",
        "The training loop is almost the same as in the first exercise of the course. Spot and understand the differences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "1nreDgJaAf7L"
      },
      "outputs": [],
      "source": [
        "def train(net, train_dl, val_dl , epochs, optimizer, loss_func):\n",
        "    # set the model on train mode\n",
        "    net.train()\n",
        "    # define arrays for evaluation\n",
        "    train_losses, valid_losses = [], []\n",
        "    train_accs, valid_accs = [], []\n",
        "\n",
        "    # loop over all epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # reset evaluation variables\n",
        "        train_loss, valid_loss = 0, 0\n",
        "        train_acc, valid_acc = 0, 0        \n",
        "        # training loop\n",
        "        for step, batch in enumerate(train_dl):\n",
        "            #print(batch[0].shape, batch[1].shape, batch[2].shape)\n",
        "            input_ids = batch[0].to(DEVICE)\n",
        "            attention_mask = batch[1].to(DEVICE)\n",
        "            labels = batch[2].to(DEVICE)            \n",
        "            # predict\n",
        "            y_hat = net(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "            # calculate loss and adjust weights\n",
        "            # reshape target tensor\n",
        "\n",
        "  \n",
        "            labels = labels.unsqueeze(1).float() # reshape target tensor and convert to float\n",
        "        \n",
        "            loss = loss_func(y_hat, labels)\n",
        "            # zero the all gradients\n",
        "            # calc gradients\n",
        "            loss.backward()\n",
        "            # update weights\n",
        "            optimizer.step()\n",
        "            # reset optimizer\n",
        "            optimizer.zero_grad()\n",
        "            # calculate evaluation kpis\n",
        "            train_loss += loss\n",
        "            #print(y_hat.shape, labels.shape)\n",
        "            #print(y_hat, labels)\n",
        "            train_acc += accuracy(y_hat, labels) \n",
        "\n",
        "        net.eval()\n",
        "        # valiadation loop\n",
        "        with torch.no_grad():\n",
        "          for step, batch in enumerate(val_dl):\n",
        "            input_ids = batch[0].to(DEVICE)\n",
        "            attention_mask = batch[1].to(DEVICE)\n",
        "            labels = batch[2].to(DEVICE)\n",
        "            # predict\n",
        "            y_hat = net(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "            # calculate evaluation kpis\n",
        "            # reshape target tensor\n",
        "            labels = labels.unsqueeze(1).float() # reshape target tensor and convert to float\n",
        "            loss = loss_func(y_hat, labels)\n",
        "            valid_loss += loss\n",
        "            valid_acc += accuracy(y_hat, labels)\n",
        "            \n",
        "\n",
        "        # calculations for evaluations\n",
        "        train_loss = train_loss/ len(train_dl)\n",
        "        train_acc = train_acc/ len(train_dl)\n",
        "        valid_loss = valid_loss/ len(val_dl)\n",
        "        valid_acc = valid_acc/ len(val_dl)\n",
        "        train_losses.append(train_loss)\n",
        "        valid_losses.append(valid_loss)\n",
        "\n",
        "        print(f'Epoch: {epoch+1} \\tTraining Loss: {train_loss:.6f} \\tTraining Acc: {train_acc:.6f} \\tValidation Loss: {valid_loss:.6f} \\tValidation Acc: {valid_acc:.6f}')\n",
        "\n",
        "    # return losses for plotting  \n",
        "    return train_losses, valid_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "QFTFQrXahJ3u",
        "outputId": "08639069-4dc1-4d1a-b8e4-5f12b016fdfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7329bf281f144c319c4594eba2c240f3",
            "7642f7df10924866bd5cc8da3e761fc0",
            "c8b2eee842374cf48f24dc66323adc6a",
            "3eedd33ade8b486982477a1bdb9c9c95",
            "8919d9b848394847b27b54940272219c",
            "44339b422c9843cbb0d1dfc6d7362c6c",
            "a2d9b45ce28443f68fb1aaa79a796e2a",
            "029ddff88c794aec90ff6248f178e09c",
            "8b3c75bfe048426291c559b409285b5d",
            "aa0da07ed5914294b7a44b0751843896",
            "a986f36ad9964f50b9352bbab6c4fd9d"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7329bf281f144c319c4594eba2c240f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.598499 \tTraining Acc: 0.795000 \tValidation Loss: 0.634413 \tValidation Acc: 0.812500\n",
            "Epoch: 2 \tTraining Loss: 0.592777 \tTraining Acc: 0.810000 \tValidation Loss: 0.634448 \tValidation Acc: 0.745536\n",
            "Epoch: 3 \tTraining Loss: 0.592442 \tTraining Acc: 0.813750 \tValidation Loss: 0.621608 \tValidation Acc: 0.776786\n",
            "Epoch: 4 \tTraining Loss: 0.592309 \tTraining Acc: 0.808750 \tValidation Loss: 0.631239 \tValidation Acc: 0.776786\n",
            "Epoch: 5 \tTraining Loss: 0.590634 \tTraining Acc: 0.810000 \tValidation Loss: 0.629591 \tValidation Acc: 0.799107\n",
            "Epoch: 6 \tTraining Loss: 0.589544 \tTraining Acc: 0.815000 \tValidation Loss: 0.640677 \tValidation Acc: 0.776786\n",
            "Epoch: 7 \tTraining Loss: 0.588525 \tTraining Acc: 0.820000 \tValidation Loss: 0.639630 \tValidation Acc: 0.758929\n",
            "Epoch: 8 \tTraining Loss: 0.587560 \tTraining Acc: 0.811250 \tValidation Loss: 0.640138 \tValidation Acc: 0.799107\n",
            "Epoch: 9 \tTraining Loss: 0.586845 \tTraining Acc: 0.823750 \tValidation Loss: 0.616475 \tValidation Acc: 0.794643\n",
            "Epoch: 10 \tTraining Loss: 0.585959 \tTraining Acc: 0.816250 \tValidation Loss: 0.633188 \tValidation Acc: 0.772321\n",
            "Epoch: 11 \tTraining Loss: 0.585256 \tTraining Acc: 0.820000 \tValidation Loss: 0.619001 \tValidation Acc: 0.799107\n",
            "Epoch: 12 \tTraining Loss: 0.584923 \tTraining Acc: 0.825000 \tValidation Loss: 0.621106 \tValidation Acc: 0.772321\n",
            "Epoch: 13 \tTraining Loss: 0.583927 \tTraining Acc: 0.822500 \tValidation Loss: 0.623782 \tValidation Acc: 0.772321\n",
            "Epoch: 14 \tTraining Loss: 0.583016 \tTraining Acc: 0.825000 \tValidation Loss: 0.614169 \tValidation Acc: 0.785714\n",
            "Epoch: 15 \tTraining Loss: 0.582815 \tTraining Acc: 0.830000 \tValidation Loss: 0.624972 \tValidation Acc: 0.785714\n",
            "Epoch: 16 \tTraining Loss: 0.581789 \tTraining Acc: 0.832500 \tValidation Loss: 0.638057 \tValidation Acc: 0.808036\n",
            "Epoch: 17 \tTraining Loss: 0.581377 \tTraining Acc: 0.832500 \tValidation Loss: 0.630528 \tValidation Acc: 0.772321\n",
            "Epoch: 18 \tTraining Loss: 0.580837 \tTraining Acc: 0.840000 \tValidation Loss: 0.628100 \tValidation Acc: 0.799107\n",
            "Epoch: 19 \tTraining Loss: 0.580343 \tTraining Acc: 0.831250 \tValidation Loss: 0.628779 \tValidation Acc: 0.763393\n",
            "Epoch: 20 \tTraining Loss: 0.580394 \tTraining Acc: 0.835000 \tValidation Loss: 0.624620 \tValidation Acc: 0.772321\n",
            "Epoch: 21 \tTraining Loss: 0.579219 \tTraining Acc: 0.832500 \tValidation Loss: 0.620697 \tValidation Acc: 0.808036\n",
            "Epoch: 22 \tTraining Loss: 0.579131 \tTraining Acc: 0.836250 \tValidation Loss: 0.625835 \tValidation Acc: 0.803571\n",
            "Epoch: 23 \tTraining Loss: 0.578471 \tTraining Acc: 0.833750 \tValidation Loss: 0.619396 \tValidation Acc: 0.794643\n",
            "Epoch: 24 \tTraining Loss: 0.578206 \tTraining Acc: 0.838750 \tValidation Loss: 0.643174 \tValidation Acc: 0.772321\n",
            "Epoch: 25 \tTraining Loss: 0.577210 \tTraining Acc: 0.842500 \tValidation Loss: 0.613628 \tValidation Acc: 0.776786\n",
            "Epoch: 26 \tTraining Loss: 0.577097 \tTraining Acc: 0.835000 \tValidation Loss: 0.639371 \tValidation Acc: 0.794643\n",
            "Epoch: 27 \tTraining Loss: 0.577024 \tTraining Acc: 0.845000 \tValidation Loss: 0.620236 \tValidation Acc: 0.821429\n",
            "Epoch: 28 \tTraining Loss: 0.576790 \tTraining Acc: 0.835000 \tValidation Loss: 0.629802 \tValidation Acc: 0.808036\n",
            "Epoch: 29 \tTraining Loss: 0.576388 \tTraining Acc: 0.836250 \tValidation Loss: 0.621175 \tValidation Acc: 0.808036\n",
            "Epoch: 30 \tTraining Loss: 0.576218 \tTraining Acc: 0.840000 \tValidation Loss: 0.609411 \tValidation Acc: 0.825893\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([tensor(0.5985, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5928, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5924, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5923, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5906, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5895, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5885, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5876, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5868, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5860, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5853, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5849, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5839, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5830, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5828, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5818, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5814, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5808, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5803, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5804, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5792, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5791, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5785, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5782, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5772, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5771, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5770, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5768, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5764, device='cuda:0', grad_fn=<DivBackward0>),\n",
              "  tensor(0.5762, device='cuda:0', grad_fn=<DivBackward0>)],\n",
              " [tensor(0.6344, device='cuda:0'),\n",
              "  tensor(0.6344, device='cuda:0'),\n",
              "  tensor(0.6216, device='cuda:0'),\n",
              "  tensor(0.6312, device='cuda:0'),\n",
              "  tensor(0.6296, device='cuda:0'),\n",
              "  tensor(0.6407, device='cuda:0'),\n",
              "  tensor(0.6396, device='cuda:0'),\n",
              "  tensor(0.6401, device='cuda:0'),\n",
              "  tensor(0.6165, device='cuda:0'),\n",
              "  tensor(0.6332, device='cuda:0'),\n",
              "  tensor(0.6190, device='cuda:0'),\n",
              "  tensor(0.6211, device='cuda:0'),\n",
              "  tensor(0.6238, device='cuda:0'),\n",
              "  tensor(0.6142, device='cuda:0'),\n",
              "  tensor(0.6250, device='cuda:0'),\n",
              "  tensor(0.6381, device='cuda:0'),\n",
              "  tensor(0.6305, device='cuda:0'),\n",
              "  tensor(0.6281, device='cuda:0'),\n",
              "  tensor(0.6288, device='cuda:0'),\n",
              "  tensor(0.6246, device='cuda:0'),\n",
              "  tensor(0.6207, device='cuda:0'),\n",
              "  tensor(0.6258, device='cuda:0'),\n",
              "  tensor(0.6194, device='cuda:0'),\n",
              "  tensor(0.6432, device='cuda:0'),\n",
              "  tensor(0.6136, device='cuda:0'),\n",
              "  tensor(0.6394, device='cuda:0'),\n",
              "  tensor(0.6202, device='cuda:0'),\n",
              "  tensor(0.6298, device='cuda:0'),\n",
              "  tensor(0.6212, device='cuda:0'),\n",
              "  tensor(0.6094, device='cuda:0')])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# Execute the train function and train the model.\n",
        "train(model, train_dl, val_dl, epochs, optimizer, loss_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGkF_RT67eEy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7329bf281f144c319c4594eba2c240f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7642f7df10924866bd5cc8da3e761fc0",
              "IPY_MODEL_c8b2eee842374cf48f24dc66323adc6a",
              "IPY_MODEL_3eedd33ade8b486982477a1bdb9c9c95"
            ],
            "layout": "IPY_MODEL_8919d9b848394847b27b54940272219c"
          }
        },
        "7642f7df10924866bd5cc8da3e761fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44339b422c9843cbb0d1dfc6d7362c6c",
            "placeholder": "â",
            "style": "IPY_MODEL_a2d9b45ce28443f68fb1aaa79a796e2a",
            "value": "100%"
          }
        },
        "c8b2eee842374cf48f24dc66323adc6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_029ddff88c794aec90ff6248f178e09c",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b3c75bfe048426291c559b409285b5d",
            "value": 30
          }
        },
        "3eedd33ade8b486982477a1bdb9c9c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa0da07ed5914294b7a44b0751843896",
            "placeholder": "â",
            "style": "IPY_MODEL_a986f36ad9964f50b9352bbab6c4fd9d",
            "value": " 30/30 [01:50&lt;00:00,  3.67s/it]"
          }
        },
        "8919d9b848394847b27b54940272219c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44339b422c9843cbb0d1dfc6d7362c6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d9b45ce28443f68fb1aaa79a796e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "029ddff88c794aec90ff6248f178e09c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b3c75bfe048426291c559b409285b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa0da07ed5914294b7a44b0751843896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a986f36ad9964f50b9352bbab6c4fd9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}